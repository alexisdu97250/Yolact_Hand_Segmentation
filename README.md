# Yolact_hand_segmentation
This project provides a hand segmentation solution using the YOLACT deep learning Network trained on Rendered Hand Pose Dataset.

The project works on images, videos as well as webcam flows and comes with an HMI that allows to :
-chose the type of input
-Process hand segmentation on the input
-Display the source data and the output
-Save the output in the test folder by pushing the button "Save"

The model has been pretrained using resnet pretrained model and then trained on the Rendered Hand Pose dataset, which is formed by digital images.

Points to improve : 
-Fasten the execution on a video flow

HMI : 
![HMI](https://user-images.githubusercontent.com/45039238/110509440-6509f080-8102-11eb-834c-d1b85217cb4c.PNG)


Examples of Hand Segmentation using the app : 

![frame_2](https://user-images.githubusercontent.com/45039238/110508861-c54c6280-8101-11eb-9a78-c967ddd40dd4.jpg)

![frame_0](https://user-images.githubusercontent.com/45039238/110509000-ed3bc600-8101-11eb-8f57-90affe262ce9.jpg)

![frame_1](https://user-images.githubusercontent.com/45039238/110508883-cbdada00-8101-11eb-91a1-78f8a1986a25.jpg)

![frame_1](https://user-images.githubusercontent.com/45039238/110508738-9d5cff00-8101-11eb-8659-baef72e705b3.jpg)




